{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1B1XLp1_UyBKzFjvvxLNScg-qXYb33vh5",
      "authorship_tag": "ABX9TyP3jJEQGbmcuLPONa1UDGN+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krazygaurav/IDL-labs/blob/master/Ex5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2_DDtiDnWSt",
        "colab_type": "text"
      },
      "source": [
        "## GROUP MEMBERS :\n",
        "\n",
        "- Aniruddh Shukla (231714)\n",
        "- Gaurav Singhal (226023)\n",
        "- Himanshi Bajaj (225827)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AINrMCeT463p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7rbFBcT49n2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/IDL-Ex-Colab/resources/ass5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvfCjpBy5OJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python prepare_data.py shakespeare_input.txt skp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaUJqJ065QxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e310d0e0-8198-4ef1-dff4-ff748d775692"
      },
      "source": [
        "from prepare_data import parse_seq\n",
        "import pickle\n",
        "\n",
        "# this is just a datasets of \"bytes\" (not understandable)\n",
        "data = tf.data.TFRecordDataset(\"skp.tfrecords\")\n",
        "\n",
        "# this maps a parser function that properly interprets the bytes over the dataset\n",
        "# (with fixed sequence length 200)\n",
        "# if you change the sequence length in preprocessing you also need to change it here\n",
        "data = data.map(lambda x: parse_seq(x, 200))\n",
        "\n",
        "# a map from characters to indices\n",
        "vocab = pickle.load(open(\"skp_vocab\", mode=\"rb\"))\n",
        "vocab_size = len(vocab)\n",
        "# inverse mapping: indices to characters\n",
        "ind_to_ch = {ind: ch for (ch, ind) in vocab.items()}\n",
        "\n",
        "print(vocab)\n",
        "print(vocab_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'3': 1, '[': 2, 'C': 3, 'x': 4, ']': 5, 'o': 6, 'G': 7, '-': 8, ':': 9, '?': 10, ' ': 11, 'h': 12, '\\n': 13, 'q': 14, 'P': 15, 'T': 16, 'Q': 17, 'V': 18, 'M': 19, 'Z': 20, 'g': 21, 'u': 22, 'I': 23, 'i': 24, 'y': 25, 'z': 26, 'A': 27, '!': 28, 'd': 29, 'B': 30, 't': 31, 'K': 32, 'l': 33, '&': 34, 'F': 35, 'm': 36, 'N': 37, 'H': 38, 'E': 39, 'O': 40, 'b': 41, 'J': 42, 'p': 43, 'X': 44, '.': 45, 'S': 46, 'v': 47, 'D': 48, 'a': 49, 'Y': 50, 'r': 51, 'R': 52, \"'\": 53, 'f': 54, '$': 55, 'c': 56, 'L': 57, 'U': 58, 'j': 59, ';': 60, 'n': 61, 'w': 62, 'W': 63, 's': 64, 'e': 65, ',': 66, 'k': 67, '<S>': 0}\n",
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4QbzNvIGsGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialization(hidden_units):\n",
        "  '''\n",
        "  Initializing the learnable parameters\n",
        "\n",
        "  @input\n",
        "  hidden_units -> Number of hidden units\n",
        "\n",
        "  @output\n",
        "  Dictionary of all parameters \n",
        "  '''\n",
        "\n",
        "  # Assuming hidden_units = 64 and Vocab_size = 28\n",
        "  # 64*68 -> Weight b/w input and hidden state \n",
        "  W_xh = tf.Variable(np.random.uniform(size=(hidden_units, vocab_size), low=-.01, high=.01).astype(np.float32), trainable=True)\n",
        "  # 64*64 -> Weight b/w hidden and hidden state\n",
        "  W_hh = tf.Variable(np.random.uniform(size=(hidden_units, hidden_units), low=-.01, high=.01).astype(np.float32), trainable=True)\n",
        "  # 68*64 -> Weight b/w hidden and output state\n",
        "  W_ho = tf.Variable(np.random.uniform(size=(vocab_size, hidden_units), low=-.01, high=.01).astype(np.float32), trainable=True)\n",
        "  \n",
        "  # 64*1 -> Bias for hidden state\n",
        "  b_h = tf.Variable(np.zeros((hidden_units, 1)), dtype=np.float32, trainable=True)\n",
        "  # 68*1 -> Bias for output state\n",
        "  b_o = tf.Variable(np.zeros((vocab_size, 1)), dtype=np.float32, trainable=True)\n",
        "\n",
        "  params = {}\n",
        "  params['W_xh'] = W_xh\n",
        "  params['W_hh'] = W_hh\n",
        "  params['W_ho'] = W_ho\n",
        "  params['b_h'] = b_h\n",
        "  params['b_o'] = b_o\n",
        "  \n",
        "  return params\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERJ8eIN3uyJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def rnn_cell(h_prev, x_t, params):\n",
        "  '''\n",
        "  Performs operation on 1 RNN cell. \n",
        "  \n",
        "  @input\n",
        "  h_prev: Hidden state of previous RNN cell. Initially it will be 0\n",
        "  x_t: Expected dimension of x_t is -> 68*128\n",
        "  params: Learning parameters\n",
        "\n",
        "  @output\n",
        "  h_next: Next hidden state. Dimension: 64*128\n",
        "  out_t: Output state for current RNN Cell. Dimension: 68*128\n",
        "  '''\n",
        "  W_xh = params['W_xh']\n",
        "  W_hh = params['W_hh']\n",
        "  W_ho = params['W_ho']\n",
        "  b_h = params['b_h']\n",
        "  b_o = params['b_o']\n",
        "\n",
        "  # Use tanh and sigmoid respectively.\n",
        "  h_next = tf.tanh(tf.matmul(W_xh, x_t) + tf.matmul(W_hh, h_prev) + b_h)\n",
        "  out_t = tf.matmul(W_ho, h_next) + b_o\n",
        "  \n",
        "  # print(\"{} x {}\".format(h_next.shape, out_t.shape))\n",
        "\n",
        "  return h_next, out_t "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zab1SoWg3eKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def rnn_forward(h_0, x_batch, params):\n",
        "  '''\n",
        "  Performs one RNN Forward pass. Loops over the given sequence and uses rnn_cell get get output and hidden cell\n",
        "\n",
        "  @input\n",
        "  h_0: Initial hidden unit values. 0\n",
        "  x_batch: One batch for a forward pass. Dimension: 128*200*68\n",
        "  params: Learning parameters\n",
        "\n",
        "  @outpu\n",
        "  Collection of hidden states\n",
        "  Output for complete Sequence\n",
        "  '''\n",
        "\n",
        "  # x_t-> (128, 200, 68)\n",
        "  m, n_T, n_x = x_batch.shape\n",
        "  # Transpose it for easier access \n",
        "  x_batch = tf.transpose(x_batch, perm=[1, 2, 0])\n",
        "\n",
        "  # n_y -> Vocab size, n_a -> hidden_units\n",
        "  n_y, n_a = params['W_ho'].shape\n",
        "  \n",
        "  # Variables to store the Next hidden states and Output\n",
        "  # n_T, n_a, m\n",
        "  h = []\n",
        "  # n_T, n_y, m\n",
        "  y_pred = []\n",
        "\n",
        "  # Next hidden state\n",
        "  h_next = h_0\n",
        "\n",
        "  for i in range(n_T):\n",
        "    x_t = x_batch[i, :, :]\n",
        "    # Sending 68*128 inputs at a time\n",
        "    h_next, out_t  = rnn_cell(h_next, x_t, params)\n",
        "    h.append(h_next)\n",
        "    y_pred.append(out_t)\n",
        "\n",
        "  return tf.stack(h), tf.stack(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFBtxTf85KWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_execution(epochs, params, optimizer):\n",
        "  '''\n",
        "  Executes the complete operation.\n",
        "\n",
        "  @inputs\n",
        "  epochs: Number of epochs to run\n",
        "  params: Learning parameters\n",
        "  optimizer: Optimizer to use\n",
        "  '''\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    losses = []\n",
        "    BATCH_SIZE = 128\n",
        "    train_data = data.batch(batch_size=BATCH_SIZE).shuffle(10000)\n",
        "    for x in train_data:\n",
        "      # initial hidden state\n",
        "      h_o =  tf.zeros((params['W_hh'].shape[0], x.shape[0]))\n",
        "      x_batch = tf.one_hot(x, vocab_size)\n",
        "\n",
        "      # Creating output. One step shifted from input seq\n",
        "      # Space OHE to add to the output\n",
        "      last_char = np.zeros(shape=(x_batch.shape[0], 1, vocab_size))\n",
        "      last_char[:, 0, 63] = 1.0\n",
        "      output = tf.concat([x_batch[:, 1:, :], last_char], axis=1)\n",
        "      \n",
        "      with tf.GradientTape() as tape:\n",
        "        h_t, logits = rnn_forward(h_o, x_batch, params)\n",
        "        logits = tf.transpose(logits, perm=[2, 0, 1])\n",
        "        logits = tf.reshape(logits, shape=[-1, logits.shape[2]])\n",
        "        output = tf.reshape(output, shape=[-1, output.shape[2]])\n",
        "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=output, logits=logits))\n",
        "        losses.append(loss)\n",
        "\n",
        "      grads = tape.gradient(loss, list(params.values()))\n",
        "      optimizer.apply_gradients(zip(grads, list(params.values())))\n",
        "    print(\"Epoch: {}, Loss: {}\".format(epoch, np.array(losses).mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al8za5yYWdfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "9eb377cc-d831-4a70-e05b-e4ed4e05e086"
      },
      "source": [
        "# Hyper-parameters\n",
        "hidden_units = 512\n",
        "epochs = 40\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Getting initialization parameters\n",
        "params = initialization(hidden_units)\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model_execution(epochs, params, optimizer)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 3.3278353214263916\n",
            "Epoch: 1, Loss: 2.8117499351501465\n",
            "Epoch: 2, Loss: 2.4492859840393066\n",
            "Epoch: 3, Loss: 2.2824795246124268\n",
            "Epoch: 4, Loss: 2.1607446670532227\n",
            "Epoch: 5, Loss: 2.066589593887329\n",
            "Epoch: 6, Loss: 1.991520881652832\n",
            "Epoch: 7, Loss: 1.9264119863510132\n",
            "Epoch: 8, Loss: 1.870708703994751\n",
            "Epoch: 9, Loss: 1.8201895952224731\n",
            "Epoch: 10, Loss: 1.775444507598877\n",
            "Epoch: 11, Loss: 1.7357341051101685\n",
            "Epoch: 12, Loss: 1.7008721828460693\n",
            "Epoch: 13, Loss: 1.6697889566421509\n",
            "Epoch: 14, Loss: 1.6431864500045776\n",
            "Epoch: 15, Loss: 1.6190650463104248\n",
            "Epoch: 16, Loss: 1.5996639728546143\n",
            "Epoch: 17, Loss: 1.5811208486557007\n",
            "Epoch: 18, Loss: 1.56381094455719\n",
            "Epoch: 19, Loss: 1.5500495433807373\n",
            "Epoch: 20, Loss: 1.5355498790740967\n",
            "Epoch: 21, Loss: 1.524636149406433\n",
            "Epoch: 22, Loss: 1.513338565826416\n",
            "Epoch: 23, Loss: 1.5030834674835205\n",
            "Epoch: 24, Loss: 1.4946669340133667\n",
            "Epoch: 25, Loss: 1.486474633216858\n",
            "Epoch: 26, Loss: 1.4793027639389038\n",
            "Epoch: 27, Loss: 1.4713902473449707\n",
            "Epoch: 28, Loss: 1.465012788772583\n",
            "Epoch: 29, Loss: 1.459468960762024\n",
            "Epoch: 30, Loss: 1.45260751247406\n",
            "Epoch: 31, Loss: 1.4509119987487793\n",
            "Epoch: 32, Loss: 1.442089557647705\n",
            "Epoch: 33, Loss: 1.4391974210739136\n",
            "Epoch: 34, Loss: 1.4340713024139404\n",
            "Epoch: 35, Loss: 1.4296051263809204\n",
            "Epoch: 36, Loss: 1.426262617111206\n",
            "Epoch: 37, Loss: 1.421849012374878\n",
            "Epoch: 38, Loss: 1.418720006942749\n",
            "Epoch: 39, Loss: 1.4159163236618042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nciw7vo9pxNU",
        "colab_type": "text"
      },
      "source": [
        "## Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKylR2t4hLsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "481bc2ec-affb-4b76-c272-690f7c22c7f1"
      },
      "source": [
        "h_next =  tf.zeros((params['W_hh'].shape[0], 1))\n",
        "ch = 'a'\n",
        "ch1 = tf.one_hot(i,depth=vocab_size)\n",
        "ch1 = tf.expand_dims(ch1,axis=1)\n",
        "softmax_list = []\n",
        "\n",
        "for time_step in range(100):\n",
        "  h_next, out_t = rnn_cell(h_next, ch1, params)\n",
        "  out_t = tf.nn.softmax(out_t, axis=0)\n",
        "  out_character = tf.transpose(tf.one_hot(tf.math.argmax(out_t, axis=0), depth=68))\n",
        "  ch1 = out_character\n",
        "  index_value = tf.math.argmax(out_t)\n",
        "  softmax_list.append(index_value.numpy()[0])\n",
        "\n",
        "seq = [ind_to_ch[ind] for ind in softmax_list]\n",
        "print(\"\".join(seq))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the sea with the world,\n",
            "That she is a man that she will stand for the world,\n",
            "That she is a man that\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}