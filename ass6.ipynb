{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ass6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1obhphod8S0PS9inhNYqRBwT9ovEH-cM9",
      "authorship_tag": "ABX9TyNglteuX/TwMxgQtaEfNcMj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxydMO0qFDep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh9d88e9j9v5",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALQXzUu5Gw7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/IDL-Ex-Colab/resources/ass6\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezVKP39TG2ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python prepare_data2.py shakespeare_input.txt skp \\\\n\\\\n+ -m 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzdLqEfOHFIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "63f018b0-7c00-474c-e01a-106fe776fa98"
      },
      "source": [
        "from prepare_data2 import parse_seq\n",
        "import pickle\n",
        "\n",
        "# this is just a datasets of \"bytes\" (not understandable)\n",
        "data = tf.data.TFRecordDataset(\"skp.tfrecords\")\n",
        "\n",
        "# this maps a parser function that properly interprets the bytes over the dataset\n",
        "# (with fixed sequence length 200)\n",
        "# if you change the sequence length in preprocessing you also need to change it here\n",
        "data = data.map(lambda x: parse_seq(x))\n",
        "\n",
        "# a map from characters to indices\n",
        "vocab = pickle.load(open(\"skp_vocab\", mode=\"rb\"))\n",
        "vocab_size = len(vocab)\n",
        "# inverse mapping: indices to characters\n",
        "ind_to_ch = {ind: ch for (ch, ind) in vocab.items()}\n",
        "\n",
        "print(vocab)\n",
        "print(vocab_size)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'N': 3, ']': 4, '!': 5, 'w': 6, 'l': 7, 'e': 8, 'M': 9, 'u': 10, '$': 11, ';': 12, 'o': 13, 'p': 14, 'I': 15, 'c': 16, 'D': 17, 'P': 18, 'F': 19, '.': 20, 'H': 21, 'T': 22, 'U': 23, ':': 24, 'a': 25, 'j': 26, 'h': 27, 'z': 28, 'B': 29, 'v': 30, 'g': 31, '-': 32, 'x': 33, 'i': 34, \"'\": 35, 'r': 36, 'y': 37, '&': 38, ',': 39, 'd': 40, 'b': 41, 'X': 42, 'k': 43, 'R': 44, 't': 45, 'W': 46, 'A': 47, 's': 48, 'f': 49, 'L': 50, 'O': 51, 'J': 52, 'Q': 53, ' ': 54, 'G': 55, 'Z': 56, '3': 57, 'm': 58, 'C': 59, 'q': 60, 'K': 61, 'Y': 62, 'V': 63, '[': 64, 'n': 65, 'S': 66, 'E': 67, '?': 68, '\\n': 69, '<PAD>': 0, '<S>': 1, '</S>': 2}\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXGH2ojUkFOM",
        "colab_type": "text"
      },
      "source": [
        "### Making fixed size sequence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfzmYJ0rSqdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = data.padded_batch(128, padded_shapes=([499]) , drop_remainder=True).shuffle(100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7lnmvwJlqGO",
        "colab_type": "text"
      },
      "source": [
        "## Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7SJ3qiIhoZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None], mask_zero=True),\n",
        "    tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0OoqB5ylwcp",
        "colab_type": "text"
      },
      "source": [
        "## Model execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_3PfqB0YBuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "e481827e-eac0-40a9-ef52-28393b928683"
      },
      "source": [
        "# Parameters\n",
        "epochs = 40\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "embedd_size = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "# Making Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Building Model\n",
        "model = build_model(vocab_size, embedd_size, rnn_units, batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  losses = []\n",
        "\n",
        "  ## Handling padding manually\n",
        "  # dataset = data.padded_batch(batch_size, padded_shapes=([500]) , drop_remainder=True).shuffle(100000)\n",
        "\n",
        "  ## Delegating handling of padding to Model \n",
        "  dataset = data.padded_batch(batch_size, drop_remainder=True).shuffle(100000)\n",
        "\n",
        "  for x_batch in dataset:\n",
        "    input = x_batch\n",
        "    target = x_batch[:, 1:]\n",
        "    mask_val = tf.math.count_nonzero(tf.sequence_mask(input, 500)).numpy()\n",
        "    model.reset_states()\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = model(input)\n",
        "      loss = tf.reduce_sum(\n",
        "          tf.keras.losses.sparse_categorical_crossentropy(\n",
        "              target, predictions[:, :-1], from_logits=True))\n",
        "      ## Calculating mean loss\n",
        "      loss = loss/mask_val\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    losses.append(loss)\n",
        "    # End of inner for-loop\n",
        "  \n",
        "  print(\"Epoch: {}, Loss: {}\".format(epoch, np.array(losses).mean()))\n",
        "  # End of outter for-loop\n",
        "\n",
        "# Saving the model\n",
        "model.save('model/model1')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.4641973376274109\n",
            "Epoch: 1, Loss: 0.4032205641269684\n",
            "Epoch: 2, Loss: 0.3545578122138977\n",
            "Epoch: 3, Loss: 0.30976733565330505\n",
            "Epoch: 4, Loss: 0.2686918377876282\n",
            "Epoch: 5, Loss: 0.23100578784942627\n",
            "Epoch: 6, Loss: 0.19692136347293854\n",
            "Epoch: 7, Loss: 0.166824072599411\n",
            "Epoch: 8, Loss: 0.1410035640001297\n",
            "Epoch: 9, Loss: 0.1195097491145134\n",
            "Epoch: 10, Loss: 0.1020113155245781\n",
            "Epoch: 11, Loss: 0.08803224563598633\n",
            "Epoch: 12, Loss: 0.07688817381858826\n",
            "Epoch: 13, Loss: 0.06801409274339676\n",
            "Epoch: 14, Loss: 0.060951586812734604\n",
            "Epoch: 15, Loss: 0.0552423894405365\n",
            "Epoch: 16, Loss: 0.050562672317028046\n",
            "Epoch: 17, Loss: 0.046557217836380005\n",
            "Epoch: 18, Loss: 0.043306730687618256\n",
            "Epoch: 19, Loss: 0.04048481583595276\n",
            "Epoch: 20, Loss: 0.0381179116666317\n",
            "Epoch: 21, Loss: 0.03601647540926933\n",
            "Epoch: 22, Loss: 0.03425099328160286\n",
            "Epoch: 23, Loss: 0.0327029675245285\n",
            "Epoch: 24, Loss: 0.03135411813855171\n",
            "Epoch: 25, Loss: 0.03012748807668686\n",
            "Epoch: 26, Loss: 0.02911739982664585\n",
            "Epoch: 27, Loss: 0.028253359720110893\n",
            "Epoch: 28, Loss: 0.02746320143342018\n",
            "Epoch: 29, Loss: 0.02679154835641384\n",
            "Epoch: 30, Loss: 0.02621491253376007\n",
            "Epoch: 31, Loss: 0.02567850984632969\n",
            "Epoch: 32, Loss: 0.025229349732398987\n",
            "Epoch: 33, Loss: 0.0248503889888525\n",
            "Epoch: 34, Loss: 0.024521203711628914\n",
            "Epoch: 35, Loss: 0.024182643741369247\n",
            "Epoch: 36, Loss: 0.023945333436131477\n",
            "Epoch: 37, Loss: 0.023655567318201065\n",
            "Epoch: 38, Loss: 0.023438753560185432\n",
            "Epoch: 39, Loss: 0.02325940504670143\n",
            "INFO:tensorflow:Assets written to: model/model1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3I9CCMteR-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "736cd372-42c0-439f-fbc2-7fed468f9155"
      },
      "source": [
        "model = tf.keras.models.load_model('model/model1')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH9MTxFFl4Uu",
        "colab_type": "text"
      },
      "source": [
        "## Text generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp8vJFfwRyBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "1d027af7-80a7-4714-a1e6-c782006dbb6b"
      },
      "source": [
        "# Making model compatibile for Batch size 1\n",
        "prediction_model = build_model(vocab_size, embedd_size, rnn_units, 1)\n",
        "prediction_model.set_weights(model.get_weights())\n",
        "\n",
        "# First character\n",
        "start_string = 'k'\n",
        "start_indices = vocab[start_string]\n",
        "start_indices = tf.expand_dims([start_indices], axis=0)\n",
        "\n",
        "# Resetting model state\n",
        "prediction_model.reset_states()\n",
        "softmax_list = []\n",
        "vocab_list = list(range(vocab_size))\n",
        "\n",
        "## Generation\n",
        "for time_step in range(1000):\n",
        "  logits = prediction_model(start_indices)\n",
        "  logits = tf.squeeze(logits, 0)\n",
        "  out_t = tf.nn.softmax(logits, 1)\n",
        "  index = np.random.choice(vocab_list , p = out_t.numpy().flatten())\n",
        "  softmax_list.append(index)\n",
        "\n",
        "  # GLITCH: Model breaks at index 0 <PAD> value. \n",
        "  if index == 0:\n",
        "    index = np.random.randint(1, vocab_size)\n",
        "  \n",
        "  start_indices = tf.expand_dims([index], axis=0)\n",
        "\n",
        "\n",
        "# print(softmax_list)\n",
        "seq = [ind_to_ch[ind] for ind in softmax_list]\n",
        "print(\"\".join(seq))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en: repair to\n",
            "Hell, master, that have taken your wife with\n",
            "us, if you find it, welcome: if you think of no\n",
            "blewhing, I'll give thee thy face, and it husbands.\n",
            "White course, my lord! you know I what you would.</S><PAD>JAMIA:</S><PAD></S><PAD>BASSANIO:\n",
            "Thou didst prove possess'd as soon stay'd before,\n",
            "So idly too much for the nobles?</S><PAD></S><PAD>PHERO:\n",
            "If it please you to say, it due so.</S><PAD>\n",
            "As thou art to thy person;\n",
            "For here's a sister of the stede, sir,\n",
            "Are mighty odds being appointed.</S><PAD>ones: I\n",
            "am almost as well as She shall be Richard.</S><PAD>OSERICHARDES:\n",
            "I'll have a sickness of my chin. Give me\n",
            "Letters from this motive.</S><PAD> stagger me.</S><PAD>llow.</S><PAD>nder: distrust\n",
            "No watching ever firm and not broke.</S><PAD>OTH\n",
            "Let us withdraw.</S><PAD>aly in pride.</S><PAD>IAGO:\n",
            "I have been told so, master.</S><PAD> AENensitors,\n",
            "Why sinks my peace what would make haste.</S><PAD> ANDenten\n",
            "Your mother chides, welcome hither.</S><PAD> ADWALD:\n",
            "'Tis already,\n",
            "And make us kill'd and patiently.</S><PAD>\n",
            "Then now we are struct them you;\n",
            "You must begin to kill me than for ourselves;\n",
            "Ourselves I have\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}